联邦学习翻译

4.4 针对敌意服务器的保护

在前面的章节中，我们假设存在一个可以编排整个训练过程的受信服务器。本节，我们讨论一种针对一个有敌意服务器的更合适的场景。特别是，我们首先调查这种环境和现有工作的挑战，然后继续描述未解决的问题以及如何使用第4.2节中讨论的技术来应对这些挑战。

4.4.1 挑战: 信道，女巫攻击，选取

在跨设备FL设置中，我们拥有一台具有大量计算资源的服务器和大量客户端，这些客户端（i）仅能与该服务器通信（如在星形网络拓扑中），并且（ii）连通性和带宽可能受到限制。 在执行给定的信任模型时，这提出了非常具体的要求。 特别是，客户端没有独立于服务器的清晰方法来在客户端之间建立安全通道。 如Reyzin等人所示。 [336]对于实际设置，在需要客户端之间专用通道的情况下，需要假设服务器在密钥分发阶段（如[73]中所做的）是诚实的（或至少是半诚实的）行为。 这包括基于MPC技术的密码解决方案。 对此假设的替代方法是将额外的参与方或公共公告板（例如，参见[341]）合并到客户端已知且可以信任的不与服务器串通的模型中。

除了信任服务器以促进专用通信渠道之外，跨设备FL的参与者还必须信任服务器以公平，诚实的方式形成客户群。控制服务器的主动恶意攻击者可能会模拟大量伪造的客户端设备（“ Sybil攻击” [140]），或者可能会从可用设备池中优先选择以前受到破坏的设备。无论采用哪种方式，对手都可以在联邦学习的一轮中控制更多的参与者，这要比简单地从总体中的对手设备的基本速率所预期的要多。这将使打破MPC中至少有一部分设备是诚实的普遍假设变得容易得多，从而破坏了协议的安全性。即使协议本身的安全性保持不变（例如，如果其安全性植根于不同的信任源，例如安全的隔离区），也可能存在以下风险：如果已知大量敌对客户端的模型更新，或由对手控制该更新，则可能会破坏其余客户的更新的隐私。注意，这些顾虑也可以适用于TEE。例如，基于TEE的混洗器也可能遭受Sybil攻击；如果将单个诚实用户的输入与来自假用户的已知输入进行混洗，那么对手将很容易在混洗输出中识别出诚实用户的价值。

请注意，在某些情况下，有可能在一轮客户端之间建立证明它们都在执行正确的协议，例如，如果客户端设备上有安全的隔离区，并且客户端之间可以进行远程证明。 在这些情况下，有可能为该回合中所有诚实的参与者建立隐私（例如，通过证明已正确遵循安全的多方计算协议，秘密且正确地添加了分布式差异隐私贡献等），即使 模型更新本身是对手已知的或由对手控制的。

4.4.2 现有方案的缺陷

鉴于FL的目标是服务器在客户数据中构建人口级别模式的模型，自然而然的隐私目标是量化并可证明地限制服务器重建单个客户输入数据的能力。这涉及形式上的定义（a）作为FL执行结果显示给服务器的客户数据的视图是什么，以及（b）这种视图的隐私泄漏是什么。在FL中，我们特别希望保证服务器可以汇总来自客户端的报告，同时以某种方式掩盖每个单独客户端的贡献。如第4.2.2节所述，这可以通过多种方式完成，通常使用一些差异性隐私的概念。这种方法有很多种，每种方法都有其自身的弱点，尤其是在FL中。例如，如已经讨论的，中央DP遭受对可信任中央服务器的访问的需求。这引出了第4.2.2节中讨论的其他有前途的私人披露方法。在这里，我们概述了这些方法的一些缺点。

本地差分隐私（LDP）

如前所述，LDP通过让每个客户端在将报告发送到中央服务器之前对其报告执行不同的私有转换，从而消除了对受信任的中央服务器的需求。 LDP假定用户的隐私完全来自该用户自己的随机性；因此，用户的隐私保证独立于所有其他用户添加的额外随机性。尽管LDP协议有效地加强了隐私并具有理论上的依据[156，135，136]，但许多结果表明，在保持实用性的同时实现局部差分隐私尤其具有挑战性，特别是在高维数据设置中[229，388， 219，51，220，424，142，111]。造成这种困难的部分原因是，引入的随机噪声的幅度必须与数据中信号的幅度相当，这可能需要合并客户端之间的报告。因此，要获得与中央设置相当的LDP效用，就需要相对较大的用户群或较大的参数选择。

混合差分隐私（HDP）

差异隐私的混合模型可以通过根据用户的信任首选项对用户进行划分来帮助减少所需用户群的大小，但是它不能为用户本地添加的噪声提供隐私放大功能。 而且，尚不清楚哪个应用领域和算法可以最佳地利用混合信任模型数据[39]。 混合模型的当前工作通常假设，无论用户信任偏好如何，其数据都来自相同的分布[39、141、53]。 放宽此假设对于FL尤其重要，因为信任首选项和实际用户数据之间的关系可能并不重要。

随机混合模型

随机混合模型可从用户的本地噪声中放大隐私，尽管它有两个缺点。首先是可信中介的要求；如果用户已经不信任管理员，那么他们不太可能会信任由管理员批准或创建的中介人（尽管TEE可能有助于弥合这一差距）。 Prochlo框架[67]（据我们所知）是唯一现有的实例。第二个缺点是随机混合模型的差异性隐私保证与参与计算的对手用户数量成比例地降低[43]。由于用户或管理员不知道该数字，因此将不确定性引入了用户所接收的真实隐私级别。在联合学习的情况下，这种风险尤其重要，因为用户（可能是对抗性的）是计算管道中的关键组成部分。当用户在本地添加自己的噪声时，安全的多方计算除了会给每个用户增加大量的计算和通信开销外，也无法解决此风险。

安全集聚协议

[73]中的安全聚合协议在聚合客户报告时具有强大的隐私保证。 此外，该协议是针对联合学习的设置而量身定制的。 例如，它对于客户端在执行过程中退出（跨设备FL的一个共同特征）是健壮的，并且可以扩展到大量参与者和更长的的向量。 但是，这种方法有几个局限性：（a）假定服务器为半诚实的服务器（仅在私钥基础结构阶段），（b）允许服务器查看全方位的聚合（可能仍会泄漏信息）， （c）稀疏向量聚合效率不高；（d）缺乏强制客户输入格式正确的能力。 如何构建一个有效，强大的安全聚合协议来解决所有这些挑战是一个悬而未决的问题。

4.4.3 分布式差分隐私训练

如果没有受信任的服务器，则可以使用分布式差异隐私（在第4.2.2节中介绍）来保护参与者的隐私。

分布式差分隐私下的通信，隐私和准确性权衡

我们指出，在分布式差异隐私中，三个性能指标是普遍关注的：准确性，隐私和通信，并且一个重要的目标是确定这些参数之间可能的折衷。 我们注意到，在没有隐私要求的情况下，关于分布估计（例如[376]）和通信复杂性的文献已经很好地研究了通信和准确性之间的权衡（有关教科书的参考，请参见[248]） 。 另一方面，在假设所有用户数据都由一个实体保存并且因此不需要进行通信的集中式设置中，从[147，146]的基础性工作开始，就已经在中央DP中广泛研究了准确性和隐私之间的权衡取舍。 

 安全混合的折衷选择

最近在混合模型中研究了这些折衷，以解决聚合的两个基本任务（目标是计算用户输入的总和）和频率估算（输入属于离散集，目标是 估算拥有给定元素的用户数）。 有关这两个问题的最新发展情况，请参见表9和表10。 两个值得注意的开放问题是（i）在改组模型中研究纯差异隐私，以及（ii）在多消息设置中确定变量选择的最佳的私密性，准确性和通信折衷情况（在最近[178]提到的单消息情况下紧紧贴合的下限）

安全集聚协议的折衷选择

研究以下类似问题以进行安全聚合将非常有意思。假设一轮有n个用户参与的联邦学习，同时假设每个用户i持有数据$x_i$。用户i对$x_i$采用算法$A(.)$来获得$y_i = A(x_i)$;在这里，$A(.)$可以被视为压缩方案和私有化方案。通过使用安全集聚协议作为黑盒，服务提供商可以观察$\overline y = \Sigma_i A(x_i)$同时可以通过计算$\hat{\overline x} = g(\overline y)$来使用$\overline{y}$估计$x_i$的真实总值$\overline{x}$。理想情况下，我们希望以最小化x估计误差的方式设计$A(.),g(.)$;形式上，我们想解决最优化问题$min_{g,A} ||g(\Sigma_i A(x_i)) - \Sigma_i x_i||$,此处$||.||$可以是$l_1$范数或者$l_2$范数。当然，在不对$g(.)$和$A(.)$施加任何约束的情况下，我们始终可以选择它们作为恒等函数，并获得0错误。然而，$A(.)$需要满足两个约束：（1）$A(.)$应该输出B位(可以认为是每个用户的通信成本),同时（2）$\overline y = \Sigma_i A(x_i)$应当是$\overline x = \Sigma_i x_i$的$(\varepsilon, \delta)-DP$版本。因此，关注的基本问题是确定在聚合时也能实现DP且同时满足固定通信预算的最优算法$A$。换个角度看问题，对于固定的$n,B,\varepsilon,\delta$,我们希望实现的最小的$l_1$或$l_2 $误差是多少？我们注意到Agarwal等人的最新工作[13]提供了一种基于均匀量化和二项式噪声相加的候选算法A。但是，尚不清楚所提出的方法是否是在这种情况下的最佳方法。因此，在上述约束下得出$l_1 $或$l_2$误差的下限是非常重要的。

隐私账户？隐私登录？

在DP的中心模型中，经常使用欠采样的高斯机制来实现DP，并且使用==矩值会计==方法在FL的各轮之间紧密跟踪隐私预算（请参见第4.3节中的讨论）。 但是，在DP的分布式设置中，由于与安全混合和安全聚合的实际实现相关的有限精度问题，因此无法使用高斯机制。 因此，该空间中的现有工作已恢复为具有离散性质的噪声分布（例如，添加伯努利噪声或二项式噪声）。 尽管这样的分布有助于解决由安全混合/聚合的基础实现所施加的有限精度约束，但它们自然不会从==矩数会计==方法中受益。 因此，一个重要的开放问题是推导针对这些分布式DP考虑的离散（和有限支持）噪声分布量身定制的==隐私权计费==技术。

处理用户掉线问题

上面的分布式DP模型假设参与的客户端在一轮中保持与服务器的连接。 但是，当大规模运行时，某些客户端会由于网络连接断开或暂时不可用而退出。 这要求分布式噪声生成机制要针对此类遗漏具有鲁棒性，并且还要影响扩张联邦学习的规模和对大量参与客户端的分析。

就健壮的分布式噪声而言，客户端退出可能会导致添加的噪声太少，无法满足差分隐私epsilon目标。 保守的方法是增加每个客户端的噪音，以便即使使用最少数量的客户端才能满足差分隐私epsilon目标，以使服务器完成安全聚合并计算总和。 但是，当更多的客户报告时，这会导致过多的噪音，这引发了一个问题，即是否有可能提供更有效的解决方案。

在扩展方面，增加参与安全聚合回合的客户端数量时，丢失的客户端数量将成为瓶颈。 同时收集足够的客户也可能是一个挑战。 为此，可以对协议进行结构化，以便客户端可以在长时间运行的聚合回合过程中多次连接，以完成其任务。 更普遍的，还有在文献中尚未系统地解决当客户可能间歇性可用时的大规模操作的问题。

新的可信赖的模型

联合学习框架利用联合学习的独特计算模型，并可能在对抗性用户的能力上做出现实的假设，从而推动了比以前使用的模型更加精细的新信任模型的开发。例如，假设多少比例的客户可能会受到对手的损害？攻击者是否有可能同时攻击服务器和大量设备，或者通常假设攻击者只能攻击一个或另一个设备就足够了吗？在联合学习中，服务器通常由众所周知的实体（例如长期存在的组织）操作。可否利用它来建立一个信任模型，在该模型中，服务器的行为是可信的但经过验证的，即，其中不会阻止服务器偏离所需协议，但是如果服务器确实偏离了协议，则很有可能被检测到（从而破坏信任，声誉，以及托管组织的潜在财务或法律地位）？

4.4.4 在训练子模型时保护隐私

有许多这种情况出现，就是其中每个客户端可能具有仅与正在训练的完整模型的相对较小部分有关的本地数据。 例如，对大型清单进行操作的模型，包括自然语言模型（对单词的清单进行操作）或内容排名模型（对内容的清单进行操作）），经常使用嵌入查找表作为神经网络的第一层。 通常，客户仅与极少量的清单项进行交互，并且在许多训练策略下，客户数据支持更新的唯一嵌入向量是与客户交互的物料相对应的嵌入向量。

再举一个例子，多任务学习策略可能是实现个性化的有效方法，但可能会产生复合模型，其中任何特定的客户端仅使用与该客户端的用户群相关联的子模型，如3.3.2节所述。

如果不关心沟通效率，那么子模型训练就像标准的联合学习：客户将在参与时下载完整模型，使用与他们相关的子模型，然后提交涵盖整个模型参数的集合的模型更新（即，除了与相关子模型相对应的条目中，其余所有地方都为零）。 但是，在部署联合学习时，通信效率通常是一个重要问题，这引发了我们是否可以实现通信效率高的子模型训练的问题。

如果没有隐私敏感信息进入客户将更新哪个特定子模型的选择，那么可能会有直接的方法来适应联合学习以实现有效的通信子模型训练。 例如，一个人可以运行多个联合学习过程的副本，每个子模型一个,或者并行（例如，客户端基于他们希望更新的子模型，选择合适的联合学习实例参与），或者按顺序（例如， 对于每轮FL，服务器都会发布要更新哪个子模型的信息），或者两者混合。 但是，尽管此方法具有较高的通信效率，但服务器可以观察到客户端选择的子模型。

能否在保持客户的子模型选择私密性的同时，实现沟通效率高的子模型联合学习？ 一种有前景的方法是将PIR用于私有子模型下载，同时使用针对稀疏向量优化的安全聚合变体来聚合模型更新[94，216，310]。

该领域中的开放问题包括表征与实际感兴趣的子模型训练问题相关联的稀疏机制，以及开发在这些稀疏机制中通信效率高的稀疏安全聚合技术。 与仅简单地使每种技术独立运行（例如，通过在两个功能的实现之间分担一些消耗）相比，是否可以共同优化私有信息检索（PIR）和安全聚合以实现更好的通信效率，这也是一个悬而未决的问题。

某些形式的局部和分布式差分隐私在这里也带来了挑战，因为通常会将噪声添加到向量的所有元素中，甚至是零。 结果，在每个客户端上添加此噪声将把原本稀疏的模型更新（即仅子模型上的非零）转换为密集的私有化模型更新（几乎在任何地方几乎都为非零）。 是否可以解决这种紧张关系是一个悬而未决的问题，即是否存在有意义的分布式差分隐私实例化，该实例化也保持了模型更新的稀疏性。

图九：具有$(\varepsilon,\delta)$-差分隐私的的多消息混合模型中的差分私有聚合协议的比较。参与方数目为n，$l$为整数参数。消息大小以位为单位。为便于阅读，我们假设$\varepsilon \le O(1)$，并且==渐近符号被抑制==。

图十：在不同模型的DP中，对大小为B的域以及n个以上的用户进行频率估计时，预期最大误差的上限和下限。 ==由固定的，正的隐私参数$\varepsilon$和$\delta$表示界限，并且渐近符号抑制因子$\overline\Theta / \overline{O}/\overline\Omega$在B和n中为多对数。==每个用户的通信以发送的位数为单位。 在所有的上限中，该协议相对于用户是对称的，并且不需要公共随机性，==我们所提到的第一个结果是隐含的。==